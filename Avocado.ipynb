{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our dataset\n",
    "data = pd.read_csv('avocado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>55979.78</td>\n",
       "      <td>1184.27</td>\n",
       "      <td>48067.99</td>\n",
       "      <td>43.61</td>\n",
       "      <td>6683.91</td>\n",
       "      <td>6556.47</td>\n",
       "      <td>127.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>83453.76</td>\n",
       "      <td>1368.92</td>\n",
       "      <td>73672.72</td>\n",
       "      <td>93.26</td>\n",
       "      <td>8318.86</td>\n",
       "      <td>8196.81</td>\n",
       "      <td>122.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>109428.33</td>\n",
       "      <td>703.75</td>\n",
       "      <td>101815.36</td>\n",
       "      <td>80.00</td>\n",
       "      <td>6829.22</td>\n",
       "      <td>6266.85</td>\n",
       "      <td>562.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>99811.42</td>\n",
       "      <td>1022.15</td>\n",
       "      <td>87315.57</td>\n",
       "      <td>85.34</td>\n",
       "      <td>11388.36</td>\n",
       "      <td>11104.53</td>\n",
       "      <td>283.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.07</td>\n",
       "      <td>74338.76</td>\n",
       "      <td>842.40</td>\n",
       "      <td>64757.44</td>\n",
       "      <td>113.00</td>\n",
       "      <td>8625.92</td>\n",
       "      <td>8061.47</td>\n",
       "      <td>564.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
       "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
       "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
       "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
       "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
       "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
       "5           5  2015-11-22          1.26      55979.78  1184.27   48067.99   \n",
       "6           6  2015-11-15          0.99      83453.76  1368.92   73672.72   \n",
       "7           7  2015-11-08          0.98     109428.33   703.75  101815.36   \n",
       "8           8  2015-11-01          1.02      99811.42  1022.15   87315.57   \n",
       "9           9  2015-10-25          1.07      74338.76   842.40   64757.44   \n",
       "\n",
       "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
       "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
       "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
       "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
       "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
       "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
       "5   43.61     6683.91     6556.47      127.44          0.0  conventional   \n",
       "6   93.26     8318.86     8196.81      122.05          0.0  conventional   \n",
       "7   80.00     6829.22     6266.85      562.37          0.0  conventional   \n",
       "8   85.34    11388.36    11104.53      283.83          0.0  conventional   \n",
       "9  113.00     8625.92     8061.47      564.45          0.0  conventional   \n",
       "\n",
       "   year  region  \n",
       "0  2015  Albany  \n",
       "1  2015  Albany  \n",
       "2  2015  Albany  \n",
       "3  2015  Albany  \n",
       "4  2015  Albany  \n",
       "5  2015  Albany  \n",
       "6  2015  Albany  \n",
       "7  2015  Albany  \n",
       "8  2015  Albany  \n",
       "9  2015  Albany  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 observations of our dataset\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column names into meaningful names (refer kaggle's avacado dataset description)\n",
    "data = data.rename(columns={'4046':'PLU_4046','4225':'PLU_4225','4770':'PLU_4770'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>PLU_4046</th>\n",
       "      <th>PLU_4225</th>\n",
       "      <th>PLU_4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>55979.78</td>\n",
       "      <td>1184.27</td>\n",
       "      <td>48067.99</td>\n",
       "      <td>43.61</td>\n",
       "      <td>6683.91</td>\n",
       "      <td>6556.47</td>\n",
       "      <td>127.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>83453.76</td>\n",
       "      <td>1368.92</td>\n",
       "      <td>73672.72</td>\n",
       "      <td>93.26</td>\n",
       "      <td>8318.86</td>\n",
       "      <td>8196.81</td>\n",
       "      <td>122.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>109428.33</td>\n",
       "      <td>703.75</td>\n",
       "      <td>101815.36</td>\n",
       "      <td>80.00</td>\n",
       "      <td>6829.22</td>\n",
       "      <td>6266.85</td>\n",
       "      <td>562.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>99811.42</td>\n",
       "      <td>1022.15</td>\n",
       "      <td>87315.57</td>\n",
       "      <td>85.34</td>\n",
       "      <td>11388.36</td>\n",
       "      <td>11104.53</td>\n",
       "      <td>283.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.07</td>\n",
       "      <td>74338.76</td>\n",
       "      <td>842.40</td>\n",
       "      <td>64757.44</td>\n",
       "      <td>113.00</td>\n",
       "      <td>8625.92</td>\n",
       "      <td>8061.47</td>\n",
       "      <td>564.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume  PLU_4046   PLU_4225  PLU_4770  \\\n",
       "0  2015-12-27          1.33      64236.62   1036.74   54454.85     48.16   \n",
       "1  2015-12-20          1.35      54876.98    674.28   44638.81     58.33   \n",
       "2  2015-12-13          0.93     118220.22    794.70  109149.67    130.50   \n",
       "3  2015-12-06          1.08      78992.15   1132.00   71976.41     72.58   \n",
       "4  2015-11-29          1.28      51039.60    941.48   43838.39     75.78   \n",
       "5  2015-11-22          1.26      55979.78   1184.27   48067.99     43.61   \n",
       "6  2015-11-15          0.99      83453.76   1368.92   73672.72     93.26   \n",
       "7  2015-11-08          0.98     109428.33    703.75  101815.36     80.00   \n",
       "8  2015-11-01          1.02      99811.42   1022.15   87315.57     85.34   \n",
       "9  2015-10-25          1.07      74338.76    842.40   64757.44    113.00   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  \n",
       "5     6683.91     6556.47      127.44          0.0  conventional  2015  Albany  \n",
       "6     8318.86     8196.81      122.05          0.0  conventional  2015  Albany  \n",
       "7     6829.22     6266.85      562.37          0.0  conventional  2015  Albany  \n",
       "8    11388.36    11104.53      283.83          0.0  conventional  2015  Albany  \n",
       "9     8625.92     8061.47      564.45          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing unnecessary column\n",
    "data = data.drop(['Unnamed: 0'],axis = 1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the type of Date feature from obj to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizing into several seasons\n",
    "def season_of_date(date):\n",
    "    year = str(date.year)\n",
    "    seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "               'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "               'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "    if date in seasons['spring']:\n",
    "        return 'spring'\n",
    "    if date in seasons['summer']:\n",
    "        return 'summer'\n",
    "    if date in seasons['autumn']:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new feature 'season' and assign the corresponding season for the Date using map function over our season_of_date function\n",
    "data['season'] = data.Date.map(season_of_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>PLU_4046</th>\n",
       "      <th>PLU_4225</th>\n",
       "      <th>PLU_4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>55979.78</td>\n",
       "      <td>1184.27</td>\n",
       "      <td>48067.99</td>\n",
       "      <td>43.61</td>\n",
       "      <td>6683.91</td>\n",
       "      <td>6556.47</td>\n",
       "      <td>127.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>83453.76</td>\n",
       "      <td>1368.92</td>\n",
       "      <td>73672.72</td>\n",
       "      <td>93.26</td>\n",
       "      <td>8318.86</td>\n",
       "      <td>8196.81</td>\n",
       "      <td>122.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>109428.33</td>\n",
       "      <td>703.75</td>\n",
       "      <td>101815.36</td>\n",
       "      <td>80.00</td>\n",
       "      <td>6829.22</td>\n",
       "      <td>6266.85</td>\n",
       "      <td>562.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>99811.42</td>\n",
       "      <td>1022.15</td>\n",
       "      <td>87315.57</td>\n",
       "      <td>85.34</td>\n",
       "      <td>11388.36</td>\n",
       "      <td>11104.53</td>\n",
       "      <td>283.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.07</td>\n",
       "      <td>74338.76</td>\n",
       "      <td>842.40</td>\n",
       "      <td>64757.44</td>\n",
       "      <td>113.00</td>\n",
       "      <td>8625.92</td>\n",
       "      <td>8061.47</td>\n",
       "      <td>564.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "      <td>autumn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume  PLU_4046   PLU_4225  PLU_4770  \\\n",
       "0 2015-12-27          1.33      64236.62   1036.74   54454.85     48.16   \n",
       "1 2015-12-20          1.35      54876.98    674.28   44638.81     58.33   \n",
       "2 2015-12-13          0.93     118220.22    794.70  109149.67    130.50   \n",
       "3 2015-12-06          1.08      78992.15   1132.00   71976.41     72.58   \n",
       "4 2015-11-29          1.28      51039.60    941.48   43838.39     75.78   \n",
       "5 2015-11-22          1.26      55979.78   1184.27   48067.99     43.61   \n",
       "6 2015-11-15          0.99      83453.76   1368.92   73672.72     93.26   \n",
       "7 2015-11-08          0.98     109428.33    703.75  101815.36     80.00   \n",
       "8 2015-11-01          1.02      99811.42   1022.15   87315.57     85.34   \n",
       "9 2015-10-25          1.07      74338.76    842.40   64757.44    113.00   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  \\\n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015   \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015   \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015   \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015   \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015   \n",
       "5     6683.91     6556.47      127.44          0.0  conventional  2015   \n",
       "6     8318.86     8196.81      122.05          0.0  conventional  2015   \n",
       "7     6829.22     6266.85      562.37          0.0  conventional  2015   \n",
       "8    11388.36    11104.53      283.83          0.0  conventional  2015   \n",
       "9     8625.92     8061.47      564.45          0.0  conventional  2015   \n",
       "\n",
       "   region  season  \n",
       "0  Albany  winter  \n",
       "1  Albany  autumn  \n",
       "2  Albany  autumn  \n",
       "3  Albany  autumn  \n",
       "4  Albany  autumn  \n",
       "5  Albany  autumn  \n",
       "6  Albany  autumn  \n",
       "7  Albany  autumn  \n",
       "8  Albany  autumn  \n",
       "9  Albany  autumn  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we can see the season feature appended at the last\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winter    5400\n",
       "summer    4319\n",
       "spring    4319\n",
       "autumn    4211\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of observations for each seasons\n",
    "data.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping date feature\n",
    "data = data.drop(['Date'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting categorical features of text data into model-understandable numerical data\n",
    "label_cols = ['type','region','season']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "data[label_cols] = data[label_cols].apply(lambda x : label.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features and \n",
    "# spliting the label encoded features into distinct features inorder to prevent our model to think that columns have data with some kind of order or hierarchy\n",
    "# column_tranformer allows us to combine several feature extraction or transformation methods into a single transformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "scale_cols = data.drop(['AveragePrice','type','year','region','season'],axis=1)\n",
    "col_trans = make_column_transformer(\n",
    "            (OneHotEncoder(), data[label_cols].columns),\n",
    "            (StandardScaler(), scale_cols.columns),\n",
    "            remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting our dataset into train and test set such that 20% of observations are considered as test set\n",
    "X = data.drop(['AveragePrice'],axis=1)\n",
    "y = data.AveragePrice\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "\n",
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  Index(['type', 'region', 'season'], dtype='object')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  Index(['Total Volume', 'PLU_4046', 'PLU_4225', 'PLU_4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags'],\n",
       "      dtype='object'))],\n",
       "                                   verbose=False)),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "pipe = make_pipeline(col_trans,linreg)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for testing set: 0.19361507178152326\n",
      "MSE for testing set: 0.0650662941485501\n",
      "RMSE for testing set: 0.2550809560679709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "print('MAE for testing set: {}'.format(mean_absolute_error(y_pred_test,y_test)))\n",
    "print('MSE for testing set: {}'.format(mean_squared_error(y_pred_test,y_test)))\n",
    "print('RMSE for testing set: {}'.format(np.sqrt(mean_squared_error(y_pred_test,y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  Index(['type', 'region', 's...\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  Index(['Total Volume', 'PLU_4046', 'PLU_4225', 'PLU_4770', 'Total Bags',\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags'],\n",
       "      dtype='object'))],\n",
       "                                   verbose=False)),\n",
       "                ('svr',\n",
       "                 SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "                     gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                     shrinking=True, tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "pipe = make_pipeline(col_trans,svr)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for testing set: 0.17173035465450415\n",
      "MSE for testing set: 0.05520054827545715\n",
      "RMSE for testing set: 0.2349479692941762\n"
     ]
    }
   ],
   "source": [
    "print('MAE for testing set: {}'.format(mean_absolute_error(y_pred_test,y_test)))\n",
    "print('MSE for testing set: {}'.format(mean_squared_error(y_pred_test,y_test)))\n",
    "print('RMSE for testing set: {}'.format(np.sqrt(mean_squared_error(y_pred_test,y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  Index(['type', 'region', 's...\n",
       "       'Small Bags', 'Large Bags', 'XLarge Bags'],\n",
       "      dtype='object'))],\n",
       "                                   verbose=False)),\n",
       "                ('decisiontreeregressor',\n",
       "                 DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                       max_features=None, max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       presort=False, random_state=None,\n",
       "                                       splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dr=DecisionTreeRegressor()\n",
    "pipe = make_pipeline(col_trans,dr)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for testing set: 0.12753972602739724\n",
      "MSE for testing set: 0.03788109589041096\n",
      "RMSE for testing set: 0.1946306653392804\n"
     ]
    }
   ],
   "source": [
    "print('MAE for testing set: {}'.format(mean_absolute_error(y_pred_test,y_test)))\n",
    "print('MSE for testing set: {}'.format(mean_squared_error(y_pred_test,y_test)))\n",
    "print('RMSE for testing set: {}'.format(np.sqrt(mean_squared_error(y_pred_test,y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  Index(['type', 'region', 's...\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=10, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_model = RandomForestRegressor()\n",
    "pipe = make_pipeline(col_trans,forest_model)\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for testing set: 0.10307835616438356\n",
      "MSE for testing set: 0.02186919397260274\n",
      "RMSE for testing set: 0.147882365319881\n"
     ]
    }
   ],
   "source": [
    "print('MAE for testing set: {}'.format(mean_absolute_error(y_pred_test,y_test)))\n",
    "print('MSE for testing set: {}'.format(mean_squared_error(y_pred_test,y_test)))\n",
    "print('RMSE for testing set: {}'.format(np.sqrt(mean_squared_error(y_pred_test,y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fab9b1f1160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((y_test-y_pred_test),bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that our residuals looked to be normally distributed and that's really a good sign which means that our model was a correct choice for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor overperfomed LinearRegression, SVR and DecisionTreeRegressor with an RMSE of 0.147.\n",
    "\n",
    "We can increase the performance to some more extent by tweaking the parameters of the models (especially for the models like RandomForestRegressor and DecisionTreeRegressor) and can use hyperparameter tuning techniques such as GridSearchCV and RandomizedSearchCV to find out the best parameters for our models!\n",
    "\n",
    "Thanks! Please do Upvote if you like my notebook. Any Suggestions are welcome!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
